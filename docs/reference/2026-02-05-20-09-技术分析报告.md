# 技术分析报告：OSW Studio 架构与部署方案

## 背景
基于用户对 `osw-studio` 项目整体架构、LLM 对接方式、代码分布以及 Hugging Face 部署方案的调研需求。

## 来源文档列表
- `GEMINI.md`: 项目章程。
- `next.config.ts`: 构建配置。
- `app/api/generate/route.ts`: LLM 核心接口。
- `lib/llm/agent.ts`: Agent 逻辑。
- `lib/llm/skill-evaluator.ts`: 技能评估逻辑。
- `osw-studio-hf/Dockerfile`: HF 部署配置。

## 1. 整体架构分析

### 1.1 技术栈
- **UI 框架**: Next.js 15 (App Router), React 19, Tailwind CSS v4, Radix UI (Headless 组件)。
- **编辑器**: Monaco Editor (VS Code 同款)，用于代码编辑。
- **存储方案**: 
    - **浏览器模式 (Browser Mode)**: 使用 IndexedDB 进行本地持久化，由 `lib/vfs` 管理虚拟文件系统。
    - **服务器模式 (Server Mode)**: 使用 `better-sqlite3` (SQLite) 进行服务端持久化，支持多站点发布。

### 1.2 LLM API 对接
- **核心逻辑位置**: `app/api/generate/route.ts`。
- **实现方式**: 
    - 该接口是一个统一的 Proxy，支持 8 种以上的供应商 (OpenRouter, OpenAI, Anthropic, Gemini, Groq, SambaNova, Ollama, LM Studio)。
    - **未使用 LangChain** 等重型框架，而是采用原生的 `fetch` 和自定义的 `streaming-parser.ts` 处理流式响应和工具调用 (Tool Calling)。
    - 支持 **Tool Calling**: 核心工具有 `shell` (文件系统操作) 和 `json_patch` (精准代码编辑)。

### 1.3 页面与 API 路由
- **前端页面 (`app/`)**:
    - `app/page.tsx`: 主入口，浏览器模式加载 `StudioApp`。
    - `app/admin/`: 后台管理系统 (项目管理、设置、技能、模板)。
    - `app/test-generation/`: 模型兼容性测试页面。
    - `app/sites/[id]/`: 已发布站点的预览/访问。
- **后端 API (`app/api/`)**:
    - `app/api/generate/`: AI 生成核心接口。
    - `app/api/shell/`: 执行虚拟 Shell 命令。
    - `app/api/sync/`: 浏览器与服务器之间的数据同步。
    - `app/api/analytics/`: 站点访问分析。

### 1.4 上下文与 Skills 实现
- **代码位置**: `lib/llm/skill-evaluator.ts` 和 `lib/llm/system-prompt.ts`。
- **实现机制**:
    - **非 LangChain 实现**: 采用了一种轻量级的“预飞行 (Pre-flight)”模式。
    - 当用户输入 Prompt 时，`skill-evaluator` 会先调用一个廉价模型（或同一模型）进行快速评估，判断哪些已启用的 Skills 与当前任务相关。
    - 相关的 Skills 内容（Markdown 格式）会被动态注入到 System Prompt 中，从而实现上下文的按需管理，减少 Token 浪费。

## 2. 构建与部署

### 2.1 构建模式
- **框架模式**: Next.js **Standalone Mode** (`output: 'standalone'`)。
- **构建产物**: 生成一个包含所有运行时依赖的最小化 `.next/standalone` 目录。

### 2.2 Hugging Face 部署方案
- **连通方式**: 
    - `osw-studio-hf` 是一个独立的仓库，存放构建后的 **Standalone** 产物和 **Dockerfile**。
    - 它不直接运行 `npm run build`，而是通过 Docker 运行预编译的代码。
- **部署细节**:
    - **Dockerfile**: 基于 `node:20-alpine`，端口固定为 `7860` (Hugging Face 默认要求)。
    - **server.js**: 这是一个自定义的入口脚本，它劫持了 Next.js 的启动过程，手动配置环境变量并启动独立服务器。
    - **数据持久化**: 在 HF 上通常是只读文件系统，但该项目巧妙地利用了浏览器端的 IndexedDB (浏览器模式) 来规避服务端存储限制。

## 3. 开发建议
1.  **参考架构**: 我们的演示项目应沿用其 `Standalone` 构建模式，以确保在 HF 上高效运行。
2.  **轻量化**: 除非业务逻辑极度复杂，否则建议维持其“原生 Fetch + 按需上下文注入”的方案，不引入 LangChain。
3.  **VFS 隔离**: 核心竞争力在于其 VFS (虚拟文件系统)，如果我们的演示项目不需要“构建网站”，可以简化这部分逻辑。

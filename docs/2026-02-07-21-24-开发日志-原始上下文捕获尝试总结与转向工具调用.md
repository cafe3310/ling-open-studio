# 2026-02-07-21-24-开发日志-原始上下文捕获尝试总结与转向工具调用

## 1. 背景 (Background)
为了深度调试模型行为，我们尝试实现一个“原始上下文查看器 (Raw Context Inspector)”，目标是将 LLM 接收到的原始消息列表和输出的完整 Token 透传到前端界面展示。

## 2. 遇到的技术挑战与问题 (Technical Challenges)

### 2.1 传输协议复杂性 (AI SDK v6)
- **Object Stream vs Byte Stream**: `createUIMessageStream` 产生的是对象流，直接传递给 Next.js `Response` 会触发 `ERR_INVALID_ARG_TYPE` 错误。虽然通过 `createUIMessageStreamResponse` 解决了序列化问题，但增加了链路的复杂性。
- **Stream Interleaving**: 在手动迭代 LangGraph 流并将其交织（Interleave）到 AI SDK UI 流的过程中，确保消息顺序和协议正确性非常困难。

### 2.2 客户端捕获瓶颈 (assistant-ui)
- **onData 失效**: 确认 `@assistant-ui/react-ai-sdk` 的运行时不支持 `onData` 回调，无法通过传输层拦截自定义数据。
- **Persistence 难题**: AI SDK 的自定义数据块分为持久化（Persistent）和瞬时（Transient）。虽然尝试通过注入 `id` 来实现持久化并利用 `useThread` 观察，但由于 `assistant-ui` 内部对 `parts` 的处理逻辑黑盒化，前端始终无法稳定抓取到自定义的 `data-context_viewer_trace` 类型数据。

### 2.3 开发成本权衡
经过多轮迭代，虽然服务端日志已能完美输出标准的 JSON Trace，但前端展示层面的集成成本超出了预期收益。

## 3. 当前现状 (Current Status)
- **后端保持增强**: 保留了 `lib/model-tracer.ts`。所有的 `General Chat` 交互依然会触发 `tracedInvoke`，在服务端控制台输出美化的 `[RAW CONTEXT TRACE]` 日志。这已能满足开发者基础的调试需求。
- **前端回滚**: 已回滚所有针对 `StudioShell` 的修改，并删除了未生效的 `ContextViewer` UI 组件及其相关的 Zustand Store。
- **API 路由**: 保持了对 `custom` 事件的处理能力，但目前主要服务于后端日志记录。

## 4. 决策与后续计划 (Decisions & Next Steps)
- **放弃前端 Inspector**: 决定不再投入精力在前端 UI 上观察原始请求，转而依赖服务端控制台。
- **重点转向工具调用 (Tool Calling)**: 接下来将全力投入到 `General Chat` 的工具调用能力建设中，包括：
    - 接入 `vfs_*` 工具。
    - 实现 `browser_js_eval` 工具。
    - 建立不同模型能力的策略分发机制（Native vs. Prompt-based）。
